{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171cc442-4873-4ca5-b31e-54e6b1f1c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import csv\n",
    "import time\n",
    "\n",
    "try:\n",
    "    # SQL Server Connection Setup with increased timeout\n",
    "    conn = pyodbc.connect(\n",
    "        'DRIVER={SQL Server};'\n",
    "        'SERVER=lds.di.unipi.it;'       \n",
    "        'DATABASE=Group_ID_7_DB;'       \n",
    "        'UID=Group_ID_7;'               \n",
    "        'PWD=SZGJIVBY;'                 \n",
    "        'Connection Timeout=60;'        \n",
    "    )\n",
    "    # \n",
    "    # Set the command timeout at the connection level (if supported)\n",
    "    conn.timeout = 300  # Command timeout set to 5 minutes\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    print(\"Connected to the SQL Server successfully!\")\n",
    "\n",
    "except pyodbc.Error as e:\n",
    "    print(\"Error connecting to SQL Server:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045fbe89-3e0d-4a32-b0d8-60f09906d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to insert data from CSV into a table\n",
    "def insert_data_from_csv(filename, table_name, has_identity=False, batch_size=1000, skip_column=None, skip_value=None):\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        headers = next(reader)  # Get column headers\n",
    "        placeholders = ', '.join(['?'] * len(headers))\n",
    "        query = f'INSERT INTO {table_name} ({\", \".join(headers)}) VALUES ({placeholders})'\n",
    "\n",
    "        # Enable IDENTITY_INSERT if required\n",
    "        if has_identity:\n",
    "            cursor.execute(f\"SET IDENTITY_INSERT {table_name} ON\")\n",
    "\n",
    "        rows_to_insert = []\n",
    "        for row in reader:\n",
    "            # Skip rows based on the given condition\n",
    "            if skip_column and skip_value:\n",
    "                column_index = headers.index(skip_column)\n",
    "                if int(row[column_index]) <= skip_value:\n",
    "                    continue\n",
    "\n",
    "            rows_to_insert.append(row)\n",
    "            if len(rows_to_insert) == batch_size:\n",
    "                try:\n",
    "                    cursor.executemany(query, rows_to_insert)\n",
    "                except pyodbc.Error as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                rows_to_insert = []  # Clear the list after batch insert\n",
    "\n",
    "        # Insert remaining rows (less than batch size)\n",
    "        if rows_to_insert:\n",
    "            try:\n",
    "                cursor.executemany(query, rows_to_insert)\n",
    "            except pyodbc.Error as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "        # Disable IDENTITY_INSERT if it was enabled\n",
    "        if has_identity:\n",
    "            cursor.execute(f\"SET IDENTITY_INSERT {table_name} OFF\")\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"Data inserted into {table_name} successfully from {filename}\")\n",
    "\n",
    "# List of tables and corresponding CSV files\n",
    "tables = [\n",
    "    ('DimCause', 'DimCause.csv', True),          # Table with identity column       DONE\n",
    "    ('DimDate', 'DimDate.csv', True),            # Table with identity column       DONE\n",
    "    ('DimGeography', 'DimGeography.csv', True),  # Table with identity column       DONE\n",
    "    ('DimWeather', 'DimWeather.csv', True),      # Table with identity column       DONE       \n",
    "]\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    conn = connect_to_database()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Loop through each table and insert data\n",
    "    for table in tables:\n",
    "        table_name = table[0]\n",
    "        filename = table[1]\n",
    "        has_identity = table[2]\n",
    "\n",
    "        # Handle optional skip conditions\n",
    "        skip_column = table[3] if len(table) > 3 else None\n",
    "        skip_value = table[4] if len(table) > 4 else None\n",
    "\n",
    "        print(f\"Inserting data into {table_name} from {filename}\")\n",
    "        try:\n",
    "            insert_data_from_csv(\n",
    "                filename, table_name, has_identity=has_identity, batch_size=500, skip_column=skip_column, skip_value=skip_value\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting data into {table_name}: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "    print(\"Data insertion for all tables completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c59a5e-22e4-45da-ab71-b3867b534b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a Person_ID already exists in the table\n",
    "def check_existing_person_ids(cursor, table_name):\n",
    "    cursor.execute(f\"SELECT Person_ID FROM {table_name}\")\n",
    "    return {row[0] for row in cursor.fetchall()}\n",
    "\n",
    "# Function to insert data from CSV into DimPerson table\n",
    "def insert_data_from_csv(filename, table_name, conn, batch_size=1000):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        existing_person_ids = check_existing_person_ids(cursor, table_name)\n",
    "        print(f\"Total existing records in {table_name}: {len(existing_person_ids)}\")\n",
    "\n",
    "        with open(filename, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            headers = next(reader)  # Get column headers\n",
    "            placeholders = ', '.join(['?'] * len(headers))\n",
    "            query = f'INSERT INTO {table_name} ({\", \".join(headers)}) VALUES ({placeholders})'\n",
    "\n",
    "            rows_to_insert = []\n",
    "            for row in reader:\n",
    "                # Skip rows with duplicate Person_ID\n",
    "                person_id_index = headers.index('Person_ID')\n",
    "                if row[person_id_index] in existing_person_ids:\n",
    "                    continue\n",
    "\n",
    "                # Convert 'Age' to integer if it exists in the headers\n",
    "                if 'Age' in headers:\n",
    "                    age_index = headers.index('Age')\n",
    "                    try:\n",
    "                        row[age_index] = int(float(row[age_index]))  # Convert to integer\n",
    "                    except ValueError:\n",
    "                        print(f\"Skipping invalid Age value: {row[age_index]}\")\n",
    "                        continue\n",
    "\n",
    "                rows_to_insert.append(row)\n",
    "                if len(rows_to_insert) == batch_size:\n",
    "                    try:\n",
    "                        cursor.executemany(query, rows_to_insert)\n",
    "                        conn.commit()\n",
    "                    except pyodbc.Error as e:\n",
    "                        print(f\"Error during batch insert for {table_name}: {e}\")\n",
    "                    rows_to_insert = []  # Clear the list after batch insert\n",
    "\n",
    "            # Insert remaining rows\n",
    "            if rows_to_insert:\n",
    "                try:\n",
    "                    cursor.executemany(query, rows_to_insert)\n",
    "                    conn.commit()\n",
    "                except pyodbc.Error as e:\n",
    "                    print(f\"Error during final batch insert for {table_name}: {e}\")\n",
    "\n",
    "            print(f\"Data inserted into {table_name} successfully from {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data into {table_name}: {e}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    conn = connect_to_database()\n",
    "\n",
    "    # Specify the table and CSV file for DimPerson\n",
    "    table_name = 'DimPerson'\n",
    "    filename = 'DimPerson.csv'\n",
    "\n",
    "    print(f\"Inserting data into {table_name} from {filename}\")\n",
    "    try:\n",
    "        insert_data_from_csv(filename, table_name, conn, batch_size=500)\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data into {table_name}: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "    print(\"Data insertion completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c18a36-644d-40fa-80a4-f24fffe9d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch existing Vehicle_IDs\n",
    "def fetch_existing_vehicle_ids(table_name):\n",
    "    try:\n",
    "        query = f\"SELECT Vehicle_ID FROM {table_name}\"\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        return {str(row[0]) for row in rows}  # Return a set of existing Vehicle_IDs\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error fetching existing Vehicle_IDs: {e}\")\n",
    "        return set()\n",
    "\n",
    "# Function to insert data from CSV into DimVehicle table\n",
    "def insert_data_with_identity(filename, table_name, batch_size=1000):\n",
    "    try:\n",
    "        # Fetch existing Vehicle_IDs\n",
    "        existing_vehicle_ids = fetch_existing_vehicle_ids(table_name)\n",
    "\n",
    "        with open(filename, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            headers = next(reader)  # Get column headers\n",
    "            placeholders = ', '.join(['?'] * len(headers))\n",
    "            query = f'INSERT INTO {table_name} ({\", \".join(headers)}) VALUES ({placeholders})'\n",
    "\n",
    "            cursor.execute(f\"SET IDENTITY_INSERT {table_name} ON\")  # Enable IDENTITY_INSERT\n",
    "\n",
    "            rows_to_insert = []\n",
    "            for row in reader:\n",
    "                # Skip rows with duplicate Vehicle_ID\n",
    "                vehicle_id_index = headers.index('Vehicle_ID')\n",
    "                if row[vehicle_id_index] in existing_vehicle_ids:\n",
    "                    continue\n",
    "\n",
    "                # Convert 'Year' to integer if it exists in the headers\n",
    "                if 'Year' in headers:\n",
    "                    year_index = headers.index('Year')\n",
    "                    try:\n",
    "                        row[year_index] = int(float(row[year_index]))  # Convert float to integer\n",
    "                    except ValueError:\n",
    "                        print(f\"Skipping invalid Year value: {row[year_index]}\")\n",
    "                        continue\n",
    "\n",
    "                rows_to_insert.append(row)\n",
    "                if len(rows_to_insert) == batch_size:\n",
    "                    try:\n",
    "                        cursor.executemany(query, rows_to_insert)\n",
    "                        conn.commit()\n",
    "                    except pyodbc.Error as e:\n",
    "                        print(f\"Error during batch insert for {table_name}: {e}\")\n",
    "                    rows_to_insert = []  # Clear the list after batch insert\n",
    "\n",
    "            # Insert remaining rows\n",
    "            if rows_to_insert:\n",
    "                try:\n",
    "                    cursor.executemany(query, rows_to_insert)\n",
    "                    conn.commit()\n",
    "                except pyodbc.Error as e:\n",
    "                    print(f\"Error during final batch insert for {table_name}: {e}\")\n",
    "\n",
    "            cursor.execute(f\"SET IDENTITY_INSERT {table_name} OFF\")  # Disable IDENTITY_INSERT\n",
    "            print(f\"Data inserted into {table_name} successfully from {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data into {table_name}: {e}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    conn = connect_to_database()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Specify the table and CSV file for DimVehicle\n",
    "    table_name = 'DimVehicle'\n",
    "    filename = 'DimVehicle.csv'\n",
    "\n",
    "    print(f\"Inserting data into {table_name} from {filename}\")\n",
    "    try:\n",
    "        insert_data_with_identity(filename, table_name, batch_size=500)\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data into {table_name}: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "    print(\"Data insertion completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e6038-edae-4591-981f-8fffd315394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get existing primary keys from the FactCrash table\n",
    "def get_existing_fact_crash_ids(table_name):\n",
    "    try:\n",
    "        query = f\"SELECT Crash_Detail_ID FROM {table_name}\"\n",
    "        cursor.execute(query)\n",
    "        return {str(row[0]) for row in cursor.fetchall()}  # Return a set of existing Crash_Detail_IDs as strings\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching existing records from {table_name}: {e}\")\n",
    "        return set()\n",
    "\n",
    "# Function to insert data from CSV into FactCrash table with IDENTITY_INSERT\n",
    "def insert_data_with_identity(filename, table_name, batch_size=1000):\n",
    "    try:\n",
    "        # Get the existing Crash_Detail_IDs to skip duplicates\n",
    "        existing_ids = get_existing_fact_crash_ids(table_name)\n",
    "        print(f\"Fetched {len(existing_ids)} existing IDs from {table_name}.\")\n",
    "\n",
    "        with open(filename, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            headers = next(reader)  # Get column headers\n",
    "            placeholders = ', '.join(['?'] * len(headers))\n",
    "            query = f'INSERT INTO {table_name} ({\", \".join(headers)}) VALUES ({placeholders})'\n",
    "\n",
    "            # Enable IDENTITY_INSERT for the table\n",
    "            cursor.execute(f\"SET IDENTITY_INSERT {table_name} ON\")\n",
    "\n",
    "            rows_to_insert = []\n",
    "            for row in reader:\n",
    "                # Skip rows with duplicate Crash_Detail_ID\n",
    "                crash_detail_id_index = headers.index('Crash_Detail_ID')\n",
    "                if str(row[crash_detail_id_index]) in existing_ids:\n",
    "                    continue  # Skip if ID already exists\n",
    "\n",
    "                # Convert numeric fields to integers if required\n",
    "                for col_name in ['num_units', 'Participant_Count', 'Weather_ID', 'Vehicle_ID', 'Date_ID', 'Geography_ID', 'Cause_ID', 'Crash_ID']:\n",
    "                    if col_name in headers:\n",
    "                        col_index = headers.index(col_name)\n",
    "                        try:\n",
    "                            row[col_index] = int(float(row[col_index]))  # Convert to integer\n",
    "                        except ValueError:\n",
    "                            print(f\"Skipping invalid value for {col_name}: {row[col_index]}\")\n",
    "                            continue\n",
    "\n",
    "                rows_to_insert.append(row)\n",
    "                if len(rows_to_insert) == batch_size:\n",
    "                    try:\n",
    "                        cursor.executemany(query, rows_to_insert)\n",
    "                        conn.commit()\n",
    "                    except pyodbc.Error as e:\n",
    "                        print(f\"Error during batch insert for {table_name}: {e}\")\n",
    "                    rows_to_insert = []  # Clear the list after batch insert\n",
    "\n",
    "            # Insert remaining rows\n",
    "            if rows_to_insert:\n",
    "                try:\n",
    "                    cursor.executemany(query, rows_to_insert)\n",
    "                    conn.commit()\n",
    "                except pyodbc.Error as e:\n",
    "                    print(f\"Error during final batch insert for {table_name}: {e}\")\n",
    "\n",
    "            # Disable IDENTITY_INSERT after the operation\n",
    "            cursor.execute(f\"SET IDENTITY_INSERT {table_name} OFF\")\n",
    "            print(f\"Data inserted into {table_name} successfully from {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data into {table_name}: {e}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    conn = connect_to_database()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Specify the table and CSV file for FactCrash\n",
    "    table_name = 'FactCrash'\n",
    "    filename = 'FactCrash.csv'\n",
    "\n",
    "    print(f\"Inserting data into {table_name} from {filename}\")\n",
    "    try:\n",
    "        insert_data_with_identity(filename, table_name, batch_size=500)\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data into {table_name}: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "    print(\"Data insertion completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8b020-1099-4fa1-859e-d821826a7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to insert data from CSV into a table\n",
    "def insert_data_from_csv(filename, table_name, has_identity=False, batch_size=1000, retries=3):\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        headers = next(reader)  # Get column headers\n",
    "        placeholders = ', '.join(['?'] * len(headers))\n",
    "        query = f'INSERT INTO {table_name} ({\", \".join(headers)}) VALUES ({placeholders})'\n",
    "\n",
    "        # Enable IDENTITY_INSERT if required\n",
    "        if has_identity:\n",
    "            cursor.execute(f\"SET IDENTITY_INSERT {table_name} ON\")\n",
    "\n",
    "        rows_to_insert = []\n",
    "        for row in reader:\n",
    "            # Skip rows with Crash_ID <= 222000\n",
    "            if int(row[0]) > 222000:  # Assuming row[0] corresponds to Crash_ID\n",
    "                rows_to_insert.append(row)\n",
    "            \n",
    "            # Insert in batches\n",
    "            if len(rows_to_insert) == batch_size:\n",
    "                attempt = 0\n",
    "                while attempt < retries:\n",
    "                    try:\n",
    "                        cursor.executemany(query, rows_to_insert)\n",
    "                        conn.commit()  # Commit the batch\n",
    "                        break  # Exit retry loop if successful\n",
    "                    except pyodbc.Error as e:\n",
    "                        print(f\"Error: {e}\")\n",
    "                        attempt += 1\n",
    "                        print(f\"Retrying batch... (Attempt {attempt}/{retries})\")\n",
    "                        time.sleep(2)  # Wait before retrying\n",
    "                rows_to_insert = []  # Clear the list after batch insert\n",
    "\n",
    "        # Insert remaining rows (less than batch size)\n",
    "        if rows_to_insert:\n",
    "            attempt = 0\n",
    "            while attempt < retries:\n",
    "                try:\n",
    "                    cursor.executemany(query, rows_to_insert)\n",
    "                    conn.commit()\n",
    "                    break\n",
    "                except pyodbc.Error as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                    attempt += 1\n",
    "                    print(f\"Retrying remaining batch... (Attempt {attempt}/{retries})\")\n",
    "                    time.sleep(2)\n",
    "\n",
    "        # Disable IDENTITY_INSERT if it was enabled\n",
    "        if has_identity:\n",
    "            cursor.execute(f\"SET IDENTITY_INSERT {table_name} OFF\")\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"Data inserted into {table_name} successfully from {filename}\")\n",
    "\n",
    "# List of tables and corresponding CSV files\n",
    "tables = [\n",
    "    ('DimCrash', 'DimCrash.csv', True),  # Table with identity column\n",
    "]\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    conn = connect_to_database()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Loop through each table and insert data\n",
    "    for table_name, filename, has_identity in tables:\n",
    "        print(f\"Inserting data into {table_name} from {filename}\")\n",
    "        try:\n",
    "            insert_data_from_csv(filename, table_name, has_identity=has_identity, batch_size=500)  # Reduced batch size for better control\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting data into {table_name}: {e}\")\n",
    "\n",
    "    conn.close()\n",
    "    print(\"Data insertion for all tables completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
