{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a587bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import math  # For handling NaN checks\n",
    "\n",
    "# Initialize counters for IDs\n",
    "cause_id_counter = 1\n",
    "date_id_counter = 1\n",
    "weather_id_counter = 1\n",
    "geography_id_counter = 1\n",
    "crash_id_counter = 1\n",
    "vehicle_id_counter = 1\n",
    "fact_crash_id_counter = 1\n",
    "\n",
    "# Initialize dictionaries for dimension tables\n",
    "cause_dict = {}\n",
    "date_dict = {}\n",
    "weather_dict = {}\n",
    "geography_dict = {}\n",
    "crash_dict = {}\n",
    "vehicle_dict = {}\n",
    "person_id_set = set()\n",
    "\n",
    "# Dictionaries to map RD_NO to various attributes\n",
    "rd_no_to_num_units = {}\n",
    "rd_no_to_participant_count = {}\n",
    "rd_no_to_date_id = {}\n",
    "rd_no_to_weather_id = {}\n",
    "rd_no_to_geography_id = {}\n",
    "rd_no_to_cause_id = {}\n",
    "rd_no_to_crash_id = {}\n",
    "rd_no_to_incident_severity = {}\n",
    "rd_no_to_geography_details = {}  # Temporary storage for police_beat, latitude, longitude\n",
    "\n",
    "# Process Crashes dataset\n",
    "with open('C:/Users/hp/OneDrive/Desktop/LDS24Project/cleaned_Dataset/cleaned_Crashes.csv', 'r') as crashes_file:\n",
    "    reader = csv.DictReader(crashes_file)\n",
    "    for row in reader:\n",
    "        rd_no = row['RD_NO']\n",
    "\n",
    "        # Process Cause Dimension\n",
    "        cause_desc = row['PRIM_CONTRIBUTORY_CAUSE']\n",
    "        if cause_desc not in cause_dict:\n",
    "            cause_dict[cause_desc] = cause_id_counter\n",
    "            cause_id_counter += 1\n",
    "        cause_id = cause_dict[cause_desc]\n",
    "        rd_no_to_cause_id[rd_no] = cause_id\n",
    "\n",
    "        # Process Date Dimension\n",
    "        crash_date_str = row['CRASH_DATE']\n",
    "        crash_date_obj = datetime.strptime(crash_date_str, '%m/%d/%Y %I:%M:%S %p')\n",
    "        crash_date_only_str = crash_date_obj.strftime('%Y-%m-%d')\n",
    "        time_of_day = crash_date_obj.strftime('%H:%M:%S')\n",
    "\n",
    "        if crash_date_only_str not in date_dict:\n",
    "            date_dict[crash_date_only_str] = (date_id_counter, time_of_day)\n",
    "            date_id_counter += 1\n",
    "\n",
    "        date_id = date_dict[crash_date_only_str][0]\n",
    "        rd_no_to_date_id[rd_no] = date_id\n",
    "\n",
    "        # Process Weather Dimension\n",
    "        weather_condition = row['WEATHER_CONDITION'].strip()\n",
    "        lighting_condition = row['LIGHTING_CONDITION'].strip()\n",
    "\n",
    "        # Define visibility condition based on weather and lighting without changing case\n",
    "        if lighting_condition == \"DAYLIGHT\" and weather_condition == \"CLEAR\":\n",
    "            visibility_condition = \"CLEAR\"\n",
    "        elif lighting_condition in [\"DUSK\", \"DAWN\", \"DARKNESS, LIGHTED ROAD\", \"DARKNESS\"] and weather_condition == \"CLEAR\":\n",
    "            visibility_condition = \"LOW LIGHT\"\n",
    "        elif weather_condition in [\"FOG\", \"SMOKE\", \"HAZE\"]:\n",
    "            visibility_condition = \"POOR (FOG, SMOKE)\"\n",
    "        elif weather_condition == \"RAIN\":\n",
    "            visibility_condition = \"POOR (RAIN)\"\n",
    "        elif weather_condition == \"SNOW\":\n",
    "            visibility_condition = \"POOR (SNOW)\"\n",
    "        else:\n",
    "            visibility_condition = \"UNKNOWN\"  # For unclassified cases\n",
    "\n",
    "\n",
    "        # Create a unique key to avoid duplicate entries in DimWeather\n",
    "        weather_key = (weather_condition, visibility_condition)\n",
    "        if weather_key not in weather_dict:\n",
    "            weather_dict[weather_key] = weather_id_counter\n",
    "            weather_id_counter += 1\n",
    "        weather_id = weather_dict[weather_key]\n",
    "        rd_no_to_weather_id[rd_no] = weather_id\n",
    "\n",
    "        # Process Geography Dimension (without CITY and STATE at this stage)\n",
    "        police_beat = row['BEAT_OF_OCCURRENCE']\n",
    "        latitude = row['LATITUDE']\n",
    "        longitude = row['LONGITUDE']\n",
    "        # Temporarily store police_beat, latitude, longitude for joining with People data later\n",
    "        rd_no_to_geography_details[rd_no] = (police_beat, latitude, longitude)\n",
    "\n",
    "        # Process Crash Dimension\n",
    "        crash_type = row['CRASH_TYPE']\n",
    "        traffic_control_device = row['TRAFFIC_CONTROL_DEVICE']\n",
    "        crash_key = (rd_no, crash_type, traffic_control_device, lighting_condition)\n",
    "\n",
    "        if crash_key not in crash_dict:\n",
    "            crash_dict[crash_key] = crash_id_counter\n",
    "            crash_id_counter += 1\n",
    "        crash_id = crash_dict[crash_key]\n",
    "        rd_no_to_crash_id[rd_no] = crash_id\n",
    "\n",
    "        # Map RD_NO to other attributes\n",
    "        rd_no_to_num_units[rd_no] = row['NUM_UNITS']\n",
    "        rd_no_to_participant_count[rd_no] = row['INJURIES_TOTAL']\n",
    "        rd_no_to_incident_severity[rd_no] = row['MOST_SEVERE_INJURY']\n",
    "\n",
    "# Process People dataset to fetch CITY and STATE for Geography Dimension\n",
    "with open('C:/Users/hp/OneDrive/Desktop/LDS24Project/cleaned_Dataset/cleaned_People.csv', 'r') as people_file:\n",
    "    reader = csv.DictReader(people_file)\n",
    "    for row in reader:\n",
    "        rd_no = row['RD_NO']\n",
    "        city = row['CITY']\n",
    "        state = row['STATE']\n",
    "        \n",
    "        # Retrieve temporary geography data from Crashes processing\n",
    "        if rd_no in rd_no_to_geography_details:\n",
    "            police_beat, latitude, longitude = rd_no_to_geography_details[rd_no]\n",
    "            geography_key = (police_beat, city, state, latitude, longitude)\n",
    "\n",
    "            if geography_key not in geography_dict:\n",
    "                geography_dict[geography_key] = geography_id_counter\n",
    "                geography_id_counter += 1\n",
    "            geography_id = geography_dict[geography_key]\n",
    "            rd_no_to_geography_id[rd_no] = geography_id\n",
    "\n",
    "# Write DimGeography table\n",
    "with open('DimGeography.csv', 'w', newline='') as dim_geography_file:\n",
    "    geography_writer = csv.writer(dim_geography_file)\n",
    "    geography_writer.writerow(['Geography_ID', 'Police_Beat', 'City', 'State', 'Latitude', 'Longitude'])\n",
    "    for (police_beat, city, state, latitude, longitude), geography_id in geography_dict.items():\n",
    "        geography_writer.writerow([geography_id, police_beat, city, state, latitude, longitude])\n",
    "\n",
    "# Write DimCause table\n",
    "with open('DimCause.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Cause_ID', 'Cause_Description'])\n",
    "    for cause_desc, cause_id in cause_dict.items():\n",
    "        writer.writerow([cause_id, cause_desc])\n",
    "\n",
    "# Write DimDate table\n",
    "with open('DimDate.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Date_ID', 'Date', 'Year', 'Quarter', 'Month', 'Day', 'Time_of_Day'])\n",
    "    for date_str, (date_id, time_of_day) in date_dict.items():\n",
    "        date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "        year = date_obj.year\n",
    "        quarter = (date_obj.month - 1) // 3 + 1\n",
    "        month = date_obj.month\n",
    "        day = date_obj.day\n",
    "        writer.writerow([date_id, date_str, year, quarter, month, day, time_of_day])\n",
    "\n",
    "# Write DimWeather table\n",
    "with open('DimWeather.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Weather_ID', 'Weather_Condition', 'Visibility_Condition'])\n",
    "    for (weather_condition, visibility_condition), weather_id in weather_dict.items():\n",
    "        writer.writerow([weather_id, weather_condition, visibility_condition])\n",
    "\n",
    "# Write DimCrash table\n",
    "with open('DimCrash.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Crash_ID', 'Crash_Type', 'Traffic_Control_Device', 'Lighting_Condition'])\n",
    "    for (rd_no, crash_type, traffic_control_device, lighting_condition), crash_id in crash_dict.items():\n",
    "        writer.writerow([crash_id, crash_type, traffic_control_device, lighting_condition])\n",
    "\n",
    "\n",
    "\n",
    "# Write DimVehicle table\n",
    "with open('DimVehicle.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Vehicle_ID', 'Make', 'Model', 'Year', 'Defects', 'Vehicle_Type'])\n",
    "    with open('C:/Users/hp/OneDrive/Desktop/LDS24Project/cleaned_Dataset/cleaned_Vehicles.csv', 'r') as vehicles_file:\n",
    "        reader = csv.DictReader(vehicles_file)\n",
    "        for row in reader:\n",
    "            vehicle_id = row['VEHICLE_ID']\n",
    "            if vehicle_id not in vehicle_dict:\n",
    "                vehicle_dict[vehicle_id] = vehicle_id_counter\n",
    "                writer.writerow([\n",
    "                    vehicle_id_counter,\n",
    "                    row['MAKE'], row['MODEL'], row['VEHICLE_YEAR'],\n",
    "                    row['VEHICLE_DEFECT'], row['VEHICLE_TYPE']\n",
    "                ])\n",
    "                vehicle_id_counter += 1\n",
    "\n",
    "# Process People dataset and write DimPerson and FactCrash tables\n",
    "with open('DimPerson.csv', 'w', newline='') as dim_person_file, \\\n",
    "     open('FactCrash.csv', 'w', newline='') as fact_crash_file:\n",
    "\n",
    "    person_writer = csv.writer(dim_person_file)\n",
    "    fact_writer = csv.writer(fact_crash_file)\n",
    "\n",
    "    person_writer.writerow(['Person_ID', 'Age', 'Age_Group', 'Role', 'Injury_Classification'])\n",
    "    fact_writer.writerow([\n",
    "        'Crash_Detail_ID', 'Damage_Amount', 'num_units', 'Incident_Severity',\n",
    "        'Participant_Count', 'Weather_ID', 'Vehicle_ID', 'Date_ID',\n",
    "        'Person_ID', 'Geography_ID', 'Cause_ID', 'Crash_ID'\n",
    "    ])\n",
    "\n",
    "    with open('C:/Users/hp/OneDrive/Desktop/LDS24Project/cleaned_Dataset/cleaned_People.csv', 'r') as people_file:\n",
    "        reader = csv.DictReader(people_file)\n",
    "        for row in reader:\n",
    "            person_id = row['PERSON_ID']\n",
    "\n",
    "            # Process Person Dimension\n",
    "            if person_id not in person_id_set:\n",
    "                age = row['AGE']\n",
    "                \n",
    "                # Check if AGE is valid and categorize\n",
    "                if age and not math.isnan(float(age)):\n",
    "                    age_int = int(float(age))\n",
    "                    # Determine Age Group based on age ranges\n",
    "                    if age_int <= 17:\n",
    "                        age_group = 'CHILD'\n",
    "                    elif 18 <= age_int <= 35:\n",
    "                        age_group = 'YOUND ADULT'\n",
    "                    elif 36 <= age_int <= 64:\n",
    "                        age_group = 'ADULT'\n",
    "                    else:\n",
    "                        age_group = 'SENIOR'\n",
    "                else:\n",
    "                    age_group = 'UNKNOWN'  # Leave blank if AGE is NaN or invalid\n",
    "\n",
    "                role = row['PERSON_TYPE']\n",
    "                injury_classification = row['INJURY_CLASSIFICATION']\n",
    "                person_writer.writerow([person_id, age, age_group, role, injury_classification])\n",
    "                person_id_set.add(person_id)\n",
    "\n",
    "            # Fact Table Entry\n",
    "            crash_detail_id = fact_crash_id_counter\n",
    "            fact_crash_id_counter += 1\n",
    "\n",
    "            # Retrieve values for FactCrash columns using RD_NO\n",
    "            damage_amount = row['DAMAGE']\n",
    "            rd_no = row['RD_NO']\n",
    "            num_units = rd_no_to_num_units.get(rd_no, '0')\n",
    "            participant_count = rd_no_to_participant_count.get(rd_no, '0')\n",
    "            weather_id = rd_no_to_weather_id.get(rd_no, '')\n",
    "            date_id = rd_no_to_date_id.get(rd_no, '')\n",
    "            geography_id = rd_no_to_geography_id.get(rd_no, '')\n",
    "            cause_id = rd_no_to_cause_id.get(rd_no, '')\n",
    "            crash_id = rd_no_to_crash_id.get(rd_no, '')\n",
    "            incident_severity = rd_no_to_incident_severity.get(rd_no, '')\n",
    "            vehicle_id = vehicle_dict.get(row['VEHICLE_ID'], '')\n",
    "\n",
    "            fact_writer.writerow([\n",
    "                crash_detail_id, damage_amount, num_units, incident_severity,\n",
    "                participant_count, weather_id, vehicle_id, date_id,\n",
    "                person_id, geography_id, cause_id, crash_id\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77a148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
